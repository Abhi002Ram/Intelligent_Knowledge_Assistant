llm:
  model_path: models/mistral-7b-instruct-v0.2.Q4_K_M.gguf
  context_window: 2048
  temperature: 0.1
  max_tokens: 300

embeddings:
  model_name: intfloat/e5-base-v2

retrieval:
  top_k: 3
