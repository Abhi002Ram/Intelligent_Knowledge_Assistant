# Known Limitations

AquilaAI is designed to reduce hallucinations, but it does not eliminate them entirely.

## System Limitations
- The platform does not guarantee zero hallucinations.
- Answers are limited to the content present in indexed documents.
- The system cannot infer or generate information not present in the knowledge base.
- Real-time or external data sources are not supported.

## Model Constraints
- Language models may occasionally produce incomplete or partially correct answers.
- Answer quality depends on document quality and retrieval accuracy.

## Usage Constraints
- AquilaAI should not be used as a sole source of truth for legal or medical decisions.
